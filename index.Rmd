---
title: "Methods for Supporting Decisions under Deep Uncertainty: A Systematic Bibliometric Review"
subtitle: "Analysis of 15,000+ Publications on Decision Support Methodologies"
author:
  - name: "Cory Whitney"
    affiliation: "University of Bonn, Germany"
    email: "cory.whitney@uni-bonn.de"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
abstract: |
  **Background:** Decision-making under deep uncertainty requires robust methodological approaches that can handle incomplete information and multiple stakeholder perspectives. This review systematically maps the methodological landscape across 15,000+ publications.
  
  **Methods:** We employ automated text mining, keyword classification, and bibliometric analysis to categorize methods, applications, and trends in decision support under uncertainty.
  
  **Keywords:** decision support, deep uncertainty, value of information, Bayesian analysis, stochastic optimization, multi-criteria decision analysis, systematic review, bibliometrics
bibliography: 
  - bib/01_introduction.bib
  - bib/01_1_review_synthesis.bib
  - bib/packages.bib
csl: apa.csl
link-citations: true
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: true
    number_sections: true
    theme: 
      version: 4
      bootswatch: flatly
    highlight: textmate
    code_folding: show
    code_download: false
    fig_width: 10
    fig_height: 6
    fig_caption: true
    keep_md: true
    df_print: kable
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}

# Global knitr options
knitr::opts_chunk$set(
  echo = TRUE,           # Show code in output
  eval = TRUE,           # Evaluate code chunks
  include = TRUE,        # Include chunk output
  message = FALSE,       # Suppress package messages
  warning = FALSE,       # Suppress warnings
  error = FALSE,         # Continue on errors (set to TRUE for debugging)
  cache = TRUE,          # Cache results for faster knitting
  cache.lazy = FALSE,    # Eager caching for large datasets
  fig.width = 10,        # Figure width in inches
  fig.height = 6,        # Figure height in inches
  fig.align = "center",  # Figure alignment
  fig.pos = "H",         # Figure position
  out.width = "90%",     # Output width
  fig.cap = TRUE,        # Enable figure captions
  dev = "png",           # Graphics device
  dpi = 300,             # Figure resolution
  tidy = FALSE,          # Don't tidy code (preserve formatting)
  results = "markup"     # How to display results
)


# Load required packages quietly
suppressPackageStartupMessages({
  library(bib2df)        # BibTeX file processing
  library(dplyr)         # Data manipulation
  library(tidyr)         # Data tidying
  library(stringr)       # String operations
  library(purrr)         # Functional programming
  library(ggplot2)       # Data visualization
  library(scales)        # Plot scales
  library(kableExtra)    # Enhanced tables
  library(DT)            # Interactive tables
  library(ggthemes)      # Additional ggplot themes
})

# Generate bibliography for all used packages
packages_to_cite <- c("bib2df", 
                      "dplyr", "tidyr", 
                      "stringr", "purrr", 
                      "ggplot2", 
                     "knitr", "bookdown", "DT")
knitr::write_bib(packages_to_cite, "bib/packages.bib")

# Set ggplot theme for consistent styling
theme_set(theme_minimal(base_size = 12, base_family = "sans"))
theme_update(
  plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
  plot.subtitle = element_text(face = "italic", size = 12, hjust = 0.5),
  axis.title = element_text(face = "bold", size = 12),
  legend.title = element_text(face = "bold"),
  panel.grid.minor = element_blank(),
  plot.caption = element_text(face = "italic", size = 10)
)

# Custom color palette for methods
method_colors <- c(
  bayesian = "#1f77b4",
  simulation = "#ff7f0e", 
  optimization = "#2ca02c",
  statistical = "#d62728",
  decision_analysis = "#9467bd",
  machine_learning = "#8c564b",
  multi_criteria = "#e377c2",
  economic_evaluation = "#7f7f7f",
  risk_analysis = "#bcbd22",
  forecasting = "#17becf"
)

```

```{r child="01_Introduction.Rmd"}
```

```{r child = "01_1_Review_and_Synthesis.rmd"}
```

# Data Import and Preprocessing

## Reading Bibliographic Data

We import bibliographic records using the `bib2df` package [@R-bib2df], converting our BibTeX file into a structured data frame for systematic processing.

```{r read_data, echo=TRUE}
# Read the bib file
bib_data <- bib2df::bib2df("bib/23_Methods_Review_Holistic_Systems.bib")
```

Our BibTeX contains (n = `r nrow(bib_data)`) citations.

## Data Cleaning and Feature Engineering

We prepare the data using `dplyr` [@R-dplyr], for annotation tracking and text consolidation.

```{r clean_data, echo=TRUE}
# Basic cleaning and text preparation
clean_bib_data <- bib_data %>%
  dplyr::mutate(
    has_annotation = !is.na(ANNOTE) & ANNOTE != "",
    annotation_text = ifelse(has_annotation, ANNOTE, ""),
    full_text = paste(TITLE, ANNOTE, sep = " "),
    year = as.numeric(YEAR)
  )
```

(`r sum(clean_bib_data$has_annotation)` of the citations have annotations.

## Method Term Discovery

We search the bibliographic record for methodological terms from titles, abstracts, keywords, and annotations.

```{r method_discovery_comprehensive, echo=TRUE}
library(tidytext)

# Combine all text fields for comprehensive analysis
all_text_data <- clean_bib_data %>%
  mutate(
    combined_text = paste(
      TITLE, 
      ifelse(!is.na(ABSTRACT), ABSTRACT, ""),
      ifelse(!is.na(KEYWORDS), KEYWORDS, ""),
      ifelse(!is.na(ANNOTE), ANNOTE, ""),
      sep = " "
    )
  )

# Tokenize all text fields to discover method terms
method_terms_comprehensive <- all_text_data %>%
  select(combined_text) %>%
  unnest_tokens(word, combined_text) %>%
  count(word, sort = TRUE) %>%
  filter(n > 5, nchar(word) > 3) %>%  # Filter for meaningful terms
  anti_join(stop_words)  # Remove common stop words
```

```{r display_method_terms, echo=FALSE}
knitr::kable(
  method_terms_comprehensive %>% head(30),
  caption = "Top 30 Most Frequent Terms Across All Text Fields",
  col.names = c("Term", "Frequency")
)
```

```{r bigram_analysis, echo=TRUE}
# Analyze multi-word method terms using n-grams
method_bigrams_comprehensive <- all_text_data %>%
  select(combined_text) %>%
  unnest_tokens(bigram, combined_text, token = "ngrams", n = 2) %>%
  count(bigram, sort = TRUE) %>%
  filter(n > 2)  # Keep only terms appearing multiple times
```

```{r display_bigrams, echo=FALSE}
knitr::kable(
  method_bigrams_comprehensive %>% head(20),
  caption = "Top 20 Most Frequent Bigrams (Two-Word Terms)",
  col.names = c("Bigram", "Frequency")
)
```

```{r method_pattern_analysis, echo=TRUE}
# Use pattern matching to find potential method terms in context
method_patterns <- c(
  "analysis", "model", "method", "approach", "framework", 
  "technique", "algorithm", "estimation", "evaluation", "simulation",
  "optimization", "bayesian", "statistical", "stochastic"
)

# Extract sentences containing methodological terms
method_sentences <- all_text_data %>%
  select(combined_text) %>%
  unnest_tokens(sentence, combined_text, token = "sentences") %>%
  filter(str_detect(tolower(sentence), paste(method_patterns, collapse = "|"))) %>%
  sample_n(10)  # Sample for review
```

## Sample Sentences Containing Methodological Terms

```{r display_method_context, echo=FALSE}
knitr::kable(
  data.frame(Example_Sentences = method_sentences$sentence)
)
```

```{r keyword_analysis, echo=TRUE}
# Specifically analyze author-provided keywords
if("KEYWORDS" %in% names(clean_bib_data)) {
  keyword_analysis <- clean_bib_data %>%
    filter(!is.na(KEYWORDS)) %>%
    select(KEYWORDS) %>%
    unnest_tokens(keyword, KEYWORDS, token = "regex", pattern = ";|,") %>%
    mutate(keyword = str_trim(tolower(keyword))) %>%
    count(keyword, sort = TRUE) %>%
    filter(n > 1, nchar(keyword) > 2)
}
```

```{r display_keywords, echo=FALSE}
if(exists("keyword_analysis")) {
  knitr::kable(
    keyword_analysis %>% head(20),
    caption = "Top 20 Author-Provided Keywords",
    col.names = c("Keyword", "Frequency")
  )
}
```

```{r method_categories}
# method categories
method_categories <- list(
  bayesian = c("bayesian", "bayes", "mcmc", "markov chain", "prior", "posterior"),
  simulation = c("simulation", "monte carlo", "stochastic", "agent-based", "discrete event"),
  optimization = c("optimization", "linear programming", "nonlinear programming", "heuristic"),
  statistical = c("regression", "anova", "time series", "survival analysis", "mixed model"),
  decision_analysis = c("decision analysis", "decision tree", "markov model", "value of information", "voi"),
  machine_learning = c("machine learning", "neural network", "random forest", "svm", "clustering"),
  multi_criteria = c("multi-criteria", "multi criteria", "analytic hierarchy", "ahp", "topsis"),
  economic_evaluation = c("cost-effectiveness", "cost-benefit", "cost-utility", "economic evaluation"),
  risk_analysis = c("risk analysis", "risk assessment", "sensitivity analysis", "uncertainty analysis")
)
```

## Automated Method Detection

We apply automated classification using a custom dictionary-based algorithm (`detect_methods_enhanced.R`) that identifies methodological approaches from text content. The `purrr` package [@R-purrr] enables efficient vectorized processing across all records. Our dual detection (full text and titles only) enables confidence scoring, where methods appearing in titles receive higher reliability weights for subsequent analysis.

```{r detect_methods}
source("R/detect_methods_enhanced.R")
# Apply method detection
clean_bib_data <- clean_bib_data %>%
  mutate(
    detected_methods = map_chr(full_text, detect_methods_enhanced),
    methods_from_title = map_chr(TITLE, detect_methods_enhanced)
  )
```

## Confidence Scoring

We assign confidence levels to method classifications based on detection location. Methods identified in titles receive higher confidence than those found only in annotations, enabling quality-weighted analysis.

```{r add_confidence_scores}
source("R/add_confidence_scores.R")
# Apply confidence scoring
clean_bib_data <- add_confidence_scores(clean_bib_data)
```

## Method Detection Validation

We validate the automated classification by reporting key metrics including detection rates and confidence level distribution. 

```{r method_detection_check_clean, echo=FALSE}
# Create a clean summary table
detection_summary <- data.frame(
  Metric = c("Total papers", 
             "Papers with methods detected", 
             "Papers with VOI",
             "High confidence classifications",
             "Medium confidence classifications",
             "Low confidence classifications"),
  Count = c(nrow(clean_bib_data),
            sum(clean_bib_data$detected_methods != ""),
            sum(clean_bib_data$has_voi),
            sum(clean_bib_data$method_confidence == "high"),
            sum(clean_bib_data$method_confidence == "medium"), 
            sum(clean_bib_data$method_confidence == "low"))
)

knitr::kable(detection_summary, 
             caption = "Method Detection Summary Statistics",
             col.names = c("Metric", "Count"))
```

## Classification Examples

We display representative examples of automated method classifications to illustrate detection accuracy and confidence assignment. 

```{r sample_results}
# Show some examples
sample_results <- clean_bib_data %>%
  filter(detected_methods != "") %>%
  select(TITLE, detected_methods, method_confidence) %>%
  head(10)

print(sample_results)
```

## Method Frequency Analysis

We quantify and visualize the distribution of methodological approaches across the literature using frequency analysis and bar chart visualization via `ggplot2` [@R-ggplot2].

```{r method_results_plot}
source("R/analyze_method_frequency.R")

method_results <- analyze_method_frequency(clean_bib_data)
print(method_results$plot)
print(method_results$counts)
```

The `method_results` reveal dominant methodological paradigms and identifies less common approaches.

## Value of Information Analysis

We conduct specialized analysis of Value of Information (VOI) literature, examining methodological patterns and temporal trends. 

```{r voi_results}
source("R/analyze_voi_papers.R")
# Analyze VOI papers
voi_results <- analyze_voi_papers(clean_bib_data)
```

`analyze_voi_papers` shows the methodological evolution and application contexts specific to VOI.

## Results Export

We compile all classification results into a structured `results_table` and export for external validation and secondary analysis.

```{r results_table}
# Create a comprehensive results table
results_table <- clean_bib_data %>%
  select(
    TITLE, 
    YEAR = year,
    HAS_ANNOTATION = has_annotation,
    DETECTED_METHODS = detected_methods, 
    CONFIDENCE = method_confidence,
    VOI = has_voi,
    BAYESIAN = has_bayesian,
    SIMULATION = has_simulation,
    UNCERTAINTY = has_uncertainty
  )

# Export for manual verification
write.csv(results_table, "data/method_detection_results.csv", row.names = FALSE)
```

## Analysis Summary

We provide a comprehensive summary of the automated classification pipeline performance and output metrics. The summary quantifies analysis scope and classification reliability.

```{r summary_report}
# Create summary report
summary_stats <- clean_bib_data %>%
  summarise(
    total_papers = n(),
    papers_with_methods = sum(detected_methods != ""),
    high_confidence = sum(method_confidence == "high")
  )

knitr::kable(summary_stats, caption = "Analysis Summary")
```

## Dominant Methodological Approaches

We identify the most prevalent methodological approaches using frequency analysis and `tidyr` [@R-tidyr] for data restructuring.

```{r top_methods}
# Show top methods
top_methods <- clean_bib_data %>%
  filter(detected_methods != "") %>%
  separate_rows(detected_methods, sep = "; ") %>%
  count(detected_methods, sort = TRUE) %>%
  head(10)

print(top_methods)
```

`top_methods` reveals the methodological ecosystem's core components, highlighting established practices and potential gaps in decision support under uncertainty literature.

## VOI Method Validation

We examine Value of Information (VOI) papers specifically to assess classification plausibility and confidence distribution within this focused methodological domain.

```{r validation_check}
# Quick validation - check if our detection makes sense
validation_check <- clean_bib_data %>%
  filter(has_voi) %>%
  select(TITLE, detected_methods, method_confidence) %>%
  arrange(desc(method_confidence))

print(validation_check)
```

`validation_check` ensures classification accuracy.

## High-Reliability Classifications

We examine the subset of classifications receiving the highest confidence rating, where methods were detected in both titles and full text.

```{r high_confidence}
# Check papers with high confidence
high_confidence <- clean_bib_data %>%
  filter(method_confidence == "high") %>%
  select(TITLE, detected_methods, methods_from_title)

print(high_confidence)
```

## Interactive Reference Browser

We provide an interactive reference browser using the `DT` package [@R-DT] for easy navigation of the analyzed literature collection.

```{r datatable_clean_bib_data}
# Minimal interactive table
DT::datatable(
  clean_bib_data %>%
    select(
      Author = AUTHOR,
      Year = YEAR,
      Title = TITLE
    ) %>%
    arrange(desc(Year), Author),
  options = list(
    pageLength = 5,
    lengthMenu = c(5, 10, 20),
    dom = 'tip'  # table, info, pagination only
  ),
  caption = "Reference List",
  rownames = FALSE,
  filter = "none"  # remove filter to save space
)
```

```{r child="References.Rmd"}
```
